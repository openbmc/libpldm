{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "263ab00d_2f981f5f",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2023-07-25T02:48:52Z",
      "side": 1,
      "message": "I don\u0027t think this is right. The instance ID is unique to the TID for the issued command for the period over which that command is valid (i.e. before timeout). However, we\u0027re not validating the TID of the received message matches the TID to which we sent the request. I think that\u0027s the primary problem here. We shouldn\u0027t need to be matching on the type and command.",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "81172233_857ff7c5",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2023-07-25T02:51:04Z",
      "side": 1,
      "message": "Note that we probably need to base this fix on top of Rashmica\u0027s fix for the `pldm_transport_recv_msg()` API:\n\nhttps://gerrit.openbmc.org/c/openbmc/libpldm/+/65337\n\nThat way we can learn the TID for the comparison we require here.",
      "parentUuid": "263ab00d_2f981f5f",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "523b9daf_bad0b2f8",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2023-07-25T03:37:18Z",
      "side": 1,
      "message": "Below one example which the instanceID can be equal.\n1. When `pldmtool platform GetPDR -a` command is called. pldmtool open the mctp socket, to start getting PDRs. -\u003e pldmtool owes one socket instance.\n\n2. At time t (ms) pldmtool send GetPDR to get the first PDRs and get the response -\u003e it has PDRs. Right after that it calls DBus interface to get next instanceId to get next PDR.\n\n3. At time t + 1 (ms) pldmd call GetSensorReading to get the sensor value. pldmd continue call GetSensorReading after each 2 ms.\n\n4. from time t + 1 to t + 1 + 32*2 pldmd sent 32 GetSensorReading request and received 32 response for that command. InstanceID of those command will occupy the range [0:31] of instance ID.\n\n5. At time t + 1 + 32*2 + 1, pldmtool get new InstanceID from D-Bus interface, it sends the GetPDR request. Because the response messages is broadcast between the mctp socket instances. The socket instance of pldmtool will feed the pldmtool with the response of GetSensorReading commands from pldmd. pldmd is free these responses but the pldmtool is not free them.\n\n6. One of instanceId of GetSensorReading response equal with the instance id in GetPDRs request.",
      "parentUuid": "81172233_857ff7c5",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9931aae6_bc17f831",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2023-07-25T04:42:36Z",
      "side": 1,
      "message": "Okay. Several things:\n\n1. Your scenario outlined above is in terms of the behaviour of the mctp-demux-daemon with its broadcasts. AF_MCTP sockets do not behave this way, therefore any work-arounds like you\u0027re proposing should go in the mctp-demux transport implementation, and not in generic code like you have here.\n\n2. If pldmtool successfully allocates an instance ID at step 5, then it must be the case that there\u0027s no in-flight request associated with that instance ID. As such, it must also be the case that draining the socket on entry to `pldm_transport_mctp_demux_recv()` is enough - any message that previously used that instance ID must already be enqueued in the socket, and can be removed prior to invoking `pldm_transport_send_msg()` to remove the ambiguity.",
      "parentUuid": "523b9daf_bad0b2f8",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e7736e56_093a933e",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2023-07-25T04:49:52Z",
      "side": 1,
      "message": "\u003e As such, it must also be the case that draining the socket on entry to `pldm_transport_mctp_demux_recv()` is enough\n\nUgh, that was meant to be `pldm_transport_mctp_demux_send()`.\n\nBut thinking about that some more, `pldm_transport_send_recv()` is only useful for requests, while the the transport-specific send and recv callbacks shouldn\u0027t care about whether they\u0027re sending or receiving requests or responses.\n\nSo maybe the draining should be done in `pldm_transport_send_recv()`, contrary to the first point in my previous comment. It will just never be the case that if the AF_MCTP transport is in use that anything needs to be drained. We can test whether or not anything needs to be drained using the `pldm_transport_poll()`. Something like:\n\n```\nfor (int i \u003d 0; i \u003c\u003d PLDM_TID_MAX \u0026\u0026 pldm_transport_poll(transport, 0) \u003d\u003d 1; i++) {\n    pldm_transport_recv_msg(...);\n    /* Discard the message */\n}\n```",
      "parentUuid": "9931aae6_bc17f831",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6aa716a6_c01b3125",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2023-07-26T06:33:41Z",
      "side": 1,
      "message": "I just updates the code to free the unexpected message before send the TX request. Because number of the response can bigger than PLDM_TID_MAX so I used `do ... while (rc \u003d\u003d PLDM_SUCCESS)`.\nLet me know your idea.",
      "parentUuid": "e7736e56_093a933e",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b3d4212a_7016d964",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2023-07-27T23:55:02Z",
      "side": 1,
      "message": "We can\u0027t have an infinite loop. My upper bound of 32 was wrong as you point out, but `32 * 256` should work?",
      "parentUuid": "6aa716a6_c01b3125",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "47090c4d_cb3075c2",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2023-07-29T02:35:01Z",
      "side": 1,
      "message": "A) That is just my example which the second GetPDRs command is sent by pldmtool after 32 GetSensorReading of pldmd. But it can be more than 32 GetSensorReading responses. It depends on:\n1. How long does it take to finish one GetSensorReading commands?\n2. How long does GetInstanceID method of D-Bus take to response new InstanceId for pldmtool?\n3. How fast the pldmd reads the sensors?\n\nMaybe \n```\nfor (int i \u003d 0; i \u003c\u003d (32 * 256) \u0026\u0026 pldm_transport_poll(transport, 0) \u003d\u003d 1; i++) {\n    pldm_transport_recv_msg(...);\n    /* Discard the message */\n}\n```\ncan make sure all existing responses will be freed (I don\u0027t think we can have 32 * 256 response messages)  but if `polling is not supported` then the above `for` will always run 32 * 256 times.\n```\n\t/* If polling isn\u0027t supported then always indicate the transport is ready */\n\tif (!transport-\u003einit_pollfd) {\n\t\treturn 1;\n\t}\n```\n\n\nB) With current implementation, I\u0027m assuming that there is some point which pldm_transport_send_recv_msg will polls all of existing messages.\nBut this assumption can be incorrect if `polling isn\u0027t supported`.\n\nIn that case, we need some way to checking there is no response using pldm_transport_recv_msg().\n \n\nC) Can you think again about original solution \u0027add checking type/command\u0027 after those discussion?\n+ It is simple.\n+ No definite case because we have time out 4800ms\n+ If we use above solutions , when we polling the existing response before sending request more response from pldmd can come -\u003e take more time.",
      "parentUuid": "b3d4212a_7016d964",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2cabcc6d_ceb5997c",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2023-07-31T02:35:30Z",
      "side": 1,
      "message": "\u003e but if polling is not supported then the above for will always run 32 256 times\n\nI assume you meant `32 * 256 (\u003d 8196)` there, not `32256`. A bound of 8196 iterations is *much* better than non-termination.\n\nBut setting that calculation aside, the main concern is around when polling is not supported.\n\nWhat we need to be clear about here is the split between *consumers* of libpldm and *implementers* of libpldm. A *consumer* of libpldm is an actor who merely uses libpldm\u0027s existing APIs and does not add or modify them. By contrast, an *implementer* of libpldm is an actor who expands or modifies libpldm\u0027s APIs.\n\nThe available transport implementations provided by libpldm are a closed set. Anyone adding a new transport implementation to libpldm is necessarily an *implementer* of libpldm by the definition above. Your concern about the case where polling is not supported would be a problem if the path could be triggered by a *consumer* of libpldm (through a consumer-supplied callback, for example), but that is not the case. Both transport implementations currently provided by libpldm have functional `poll()` implementations. An implementer introducing a new transport must test that the library\u0027s behaviours are sensible for their new transport. At the point of that testing we may have to change the implementation of `pldm_transport_send_recv()` to accommodate any unique behaviours of the new transport implementation. But that\u0027s fine, because they\u0027re just implementation details, and are not changes in behaviour of a public API.\n\n\u003e C) Can you think again about original solution \u0027add checking type/command\u0027 after those discussion?\n\u003e\n\u003e - It is simple.\n\u003e - No definite case because we have time out 4800ms\n\u003e - If we use above solutions , when we polling the existing response before sending request more response from pldmd can come -\u003e take more time.\n\nI still prefer we do not do this. This test is not required by the specification and IMO it muddies the waters of the implementation. Draining the socket prior to send deals with some implementation warts that are beyond the specification and its implementation matches that concern.\n\nRegarding the timeouts and taking more time, no matter which approach we take we still have to process the the same number of messages from the socket in a given scenario. The point of difference is *where* we discard them in time and in the implementation. If anything, I think my proposal has a positive impact on potential timeouts because we discard any messages in the socket prior to sending the request (starting the timer), which means that the timeout period more accurately reflects the intent of the spec.\n\nWhat are your thoughts?",
      "parentUuid": "47090c4d_cb3075c2",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "51b5934e_33951fd1",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2023-07-31T03:18:04Z",
      "side": 1,
      "message": "\u003e \u003e but if polling is not supported then the above for will always run 32 256 times\n\u003e \n\u003e I assume you meant `32 * 256 (\u003d 8196)` there, not `32256`. A bound of 8196 iterations is *much* better than non-termination.\n\nI missed `*` in my previous comment. I mean \"but if polling is not supported then the above for will always run 32*256 times\" or `8196 times` as your correction.\n\n\u003e \n\u003e But setting that calculation aside, the main concern is around when polling is not supported.\n\u003e \n\u003e What we need to be clear about here is the split between *consumers* of libpldm and *implementers* of libpldm. A *consumer* of libpldm is an actor who merely uses libpldm\u0027s existing APIs and does not add or modify them. By contrast, an *implementer* of libpldm is an actor who expands or modifies libpldm\u0027s APIs.\n\u003e \n\u003e The available transport implementations provided by libpldm are a closed set. Anyone adding a new transport implementation to libpldm is necessarily an *implementer* of libpldm by the definition above. Your concern about the case where polling is not supported would be a problem if the path could be triggered by a *consumer* of libpldm (through a consumer-supplied callback, for example), but that is not the case. Both transport implementations currently provided by libpldm have functional `poll()` implementations. An implementer introducing a new transport must test that the library\u0027s behaviours are sensible for their new transport. At the point of that testing we may have to change the implementation of `pldm_transport_send_recv()` to accommodate any unique behaviours of the new transport implementation. But that\u0027s fine, because they\u0027re just implementation details, and are not changes in behaviour of a public API.\n\nSo as you said the poll will always be supported. That mean at some point the `poll()` will return time out.\n\n\u003e \n\u003e \u003e C) Can you think again about original solution \u0027add checking type/command\u0027 after those discussion?\n\u003e \u003e\n\u003e \u003e - It is simple.\n\u003e \u003e - No definite case because we have time out 4800ms\n\u003e \u003e - If we use above solutions , when we polling the existing response before sending request more response from pldmd can come -\u003e take more time.\n\u003e \n\u003e I still prefer we do not do this. This test is not required by the specification and IMO it muddies the waters of the implementation. Draining the socket prior to send deals with some implementation warts that are beyond the specification and its implementation matches that concern.\n\u003e \n\u003e Regarding the timeouts and taking more time, no matter which approach we take we still have to process the the same number of messages from the socket in a given scenario. The point of difference is *where* we discard them in time and in the implementation. If anything, I think my proposal has a positive impact on potential timeouts because we discard any messages in the socket prior to sending the request (starting the timer), which means that the timeout period more accurately reflects the intent of the spec.\n\u003e \n\u003e What are your thoughts?\n\nI knew that adding there is no requirement to check type and index command in the specs. Anyways, I agree that we should follow the spec. So let forget about option C.",
      "parentUuid": "2cabcc6d_ceb5997c",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "94962397_705084b5",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2023-07-31T03:27:16Z",
      "side": 1,
      "message": "So the final question is which solution will we choose? \n```\nfor (int i \u003d 0; i \u003c\u003d 8196 \u0026\u0026 pldm_transport_poll(transport, 0) \u003d\u003d 1; i++) {\n    pldm_transport_recv_msg(...);\n    /* Discard the message */\n}\n```\n\nor \n```\ndo\n{\n    pldm_transport_recv_msg(...);\n    /* Discard the message */\n}\nwhile (pldm_transport_poll(transport, 0) \u003d\u003d 1);\n```\nIMO, there is the point which `pldm_transport_poll(transport, 0)` will return 0 (time out) so both codes will be exited at some points (no infinity loop).\nBecause there is no guarantee that there are only 8196 messages which are not consumed by pldmtool so I think `do while` is the good way to go.",
      "parentUuid": "51b5934e_33951fd1",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "eae867d9_59e0bb70",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2023-07-31T04:19:38Z",
      "side": 1,
      "message": "\u003e IMO, there is the point which pldm_transport_poll(transport, 0) will return 0 (time out) so both codes will be exited at some points (no infinity loop).\n\nI don\u0027t think we can state that in general. We can\u0027t be putting constraints, beyond the PLDM specification, on the behaviour of processes that are running concurrent to ours. Applications running concurrent to ours can continue sending messages as much as they wish (especially currently, given our violation of the spec with the lack of per-TID queuing), which we will keep receiving due to the behaviour of mctp-demux-daemon.\n\n\u003e Because there is no guarantee that there are only 8196 messages which are not consumed by pldmtool\n\nIf you\u0027re going to state that then you\u0027re acknowledging that the do-while loop doesn\u0027t really have a bound. We need a bound so execution doesn\u0027t just disappear into libpldm and never return to the application (this is also true of your proposal in option C). If we hit the 8196 limit we should return an error, as there isn\u0027t really any other sensible bound that I can think of. We need to choose an error which is appropriate to return.",
      "parentUuid": "94962397_705084b5",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "cfcec8aa_8bdae723",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2023-07-31T07:56:22Z",
      "side": 1,
      "message": "How about adding new return `PLDM_REQUESTER_SOCKET_BUSY \u003d -13,`to `pldm_requester_error_codes`?\n```\ntypedef enum pldm_requester_error_codes {\n\tPLDM_REQUESTER_SUCCESS \u003d 0,\n\tPLDM_REQUESTER_OPEN_FAIL \u003d -1,\n\tPLDM_REQUESTER_NOT_PLDM_MSG \u003d -2,\n\tPLDM_REQUESTER_NOT_RESP_MSG \u003d -3,\n\tPLDM_REQUESTER_NOT_REQ_MSG \u003d -4,\n\tPLDM_REQUESTER_RESP_MSG_TOO_SMALL \u003d -5,\n\tPLDM_REQUESTER_INSTANCE_ID_MISMATCH \u003d -6,\n\tPLDM_REQUESTER_SEND_FAIL \u003d -7,\n\tPLDM_REQUESTER_RECV_FAIL \u003d -8,\n\tPLDM_REQUESTER_INVALID_RECV_LEN \u003d -9,\n\tPLDM_REQUESTER_SETUP_FAIL \u003d -10,\n\tPLDM_REQUESTER_INVALID_SETUP \u003d -11,\n\tPLDM_REQUESTER_POLL_FAIL \u003d -12,\n\tPLDM_REQUESTER_SOCKET_BUSY \u003d -13,\n} pldm_requester_rc_t;\n```",
      "parentUuid": "eae867d9_59e0bb70",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "67a7339d_5e67562a",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2023-07-31T08:04:22Z",
      "side": 1,
      "message": "yeah, though maybe `s/SOCKET/TRANSPORT/` (`PLDM_REQUESTER_TRANSPORT_BUSY`) so we\u0027re not leaking implementation details?",
      "parentUuid": "cfcec8aa_8bdae723",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4f5e2c43_ecb3cc97",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2023-07-31T08:27:55Z",
      "side": 1,
      "message": "Ok, Let use `PLDM_REQUESTER_TRANSPORT_BUSY`.",
      "parentUuid": "67a7339d_5e67562a",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "369fb11f_542103d5",
        "filename": "src/transport/transport.c",
        "patchSetId": 2
      },
      "lineNbr": 196,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2023-07-31T14:28:09Z",
      "side": 1,
      "message": "Updated.",
      "parentUuid": "4f5e2c43_ecb3cc97",
      "revId": "0adc2f2df90c2155c01f74e2cdd7a42dac73029f",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    }
  ]
}